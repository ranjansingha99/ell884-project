{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11591512,"sourceType":"datasetVersion","datasetId":7268654}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-05-09T10:47:55.248063Z","iopub.execute_input":"2025-05-09T10:47:55.249077Z","iopub.status.idle":"2025-05-09T10:47:55.516197Z","shell.execute_reply.started":"2025-05-09T10:47:55.249051Z","shell.execute_reply":"2025-05-09T10:47:55.515597Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/dialoconan/DIALOCONAN.csv\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"## Install Dependencies","metadata":{}},{"cell_type":"code","source":"# Install dependencies\n!pip install transformers==4.47.0 datasets torch pandas numpy nltk sacrebleu rouge-score bert-score","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-09T10:47:55.517185Z","iopub.execute_input":"2025-05-09T10:47:55.517474Z","iopub.status.idle":"2025-05-09T10:49:27.680375Z","shell.execute_reply.started":"2025-05-09T10:47:55.517457Z","shell.execute_reply":"2025-05-09T10:49:27.679661Z"}},"outputs":[{"name":"stdout","text":"Collecting transformers==4.47.0\n  Downloading transformers-4.47.0-py3-none-any.whl.metadata (43 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.5/43.5 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.5.0)\nRequirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.5.1+cu124)\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.3)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (1.26.4)\nRequirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\nCollecting sacrebleu\n  Downloading sacrebleu-2.5.1-py3-none-any.whl.metadata (51 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.8/51.8 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting rouge-score\n  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nCollecting bert-score\n  Downloading bert_score-0.3.13-py3-none-any.whl.metadata (15 kB)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers==4.47.0) (3.18.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from transformers==4.47.0) (0.30.2)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers==4.47.0) (24.2)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.47.0) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.47.0) (2024.11.6)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers==4.47.0) (2.32.3)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers==4.47.0) (0.21.0)\nRequirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.47.0) (0.5.2)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers==4.47.0) (4.67.1)\nRequirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (19.0.1)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\nRequirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\nCollecting fsspec<=2024.12.0,>=2023.1.0 (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets)\n  Downloading fsspec-2024.12.0-py3-none-any.whl.metadata (11 kB)\nRequirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.16)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.1)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.5.147 (from torch)\n  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nCollecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy) (2.4.1)\nRequirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.1.8)\nRequirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.4.2)\nCollecting portalocker (from sacrebleu)\n  Downloading portalocker-3.1.1-py3-none-any.whl.metadata (8.6 kB)\nRequirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (0.9.0)\nRequirement already satisfied: colorama in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (0.4.6)\nRequirement already satisfied: lxml in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (5.3.1)\nRequirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from rouge-score) (1.4.0)\nRequirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from rouge-score) (1.17.0)\nRequirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from bert-score) (3.7.5)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.2.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.19.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.47.0) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.47.0) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.47.0) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.47.0) (2025.1.31)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert-score) (1.3.1)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert-score) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert-score) (4.56.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert-score) (1.4.8)\nRequirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert-score) (11.1.0)\nRequirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert-score) (3.2.1)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy) (2024.2.0)\nDownloading transformers-4.47.0-py3-none-any.whl (10.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.1/10.1 MB\u001b[0m \u001b[31m90.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m85.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading sacrebleu-2.5.1-py3-none-any.whl (104 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.1/104.1 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading bert_score-0.3.13-py3-none-any.whl (61 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.1/61.1 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading fsspec-2024.12.0-py3-none-any.whl (183 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.9/183.9 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading portalocker-3.1.1-py3-none-any.whl (19 kB)\nBuilding wheels for collected packages: rouge-score\n  Building wheel for rouge-score (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for rouge-score: filename=rouge_score-0.1.2-py3-none-any.whl size=24935 sha256=c6d813a53a78d9d23bb068d1549969feb39f1c51a361ad6673a77a8d650128a5\n  Stored in directory: /root/.cache/pip/wheels/1e/19/43/8a442dc83660ca25e163e1bd1f89919284ab0d0c1475475148\nSuccessfully built rouge-score\nInstalling collected packages: portalocker, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cublas-cu12, fsspec, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, transformers, sacrebleu, rouge-score, bert-score\n  Attempting uninstall: nvidia-nvjitlink-cu12\n    Found existing installation: nvidia-nvjitlink-cu12 12.8.93\n    Uninstalling nvidia-nvjitlink-cu12-12.8.93:\n      Successfully uninstalled nvidia-nvjitlink-cu12-12.8.93\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.9.90\n    Uninstalling nvidia-curand-cu12-10.3.9.90:\n      Successfully uninstalled nvidia-curand-cu12-10.3.9.90\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.3.3.83\n    Uninstalling nvidia-cufft-cu12-11.3.3.83:\n      Successfully uninstalled nvidia-cufft-cu12-11.3.3.83\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.8.4.1\n    Uninstalling nvidia-cublas-cu12-12.8.4.1:\n      Successfully uninstalled nvidia-cublas-cu12-12.8.4.1\n  Attempting uninstall: fsspec\n    Found existing installation: fsspec 2025.3.2\n    Uninstalling fsspec-2025.3.2:\n      Successfully uninstalled fsspec-2025.3.2\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.5.8.93\n    Uninstalling nvidia-cusparse-cu12-12.5.8.93:\n      Successfully uninstalled nvidia-cusparse-cu12-12.5.8.93\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.7.3.90\n    Uninstalling nvidia-cusolver-cu12-11.7.3.90:\n      Successfully uninstalled nvidia-cusolver-cu12-11.7.3.90\n  Attempting uninstall: transformers\n    Found existing installation: transformers 4.51.1\n    Uninstalling transformers-4.51.1:\n      Successfully uninstalled transformers-4.51.1\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ngcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.12.0 which is incompatible.\nbigframes 1.36.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\npylibcugraph-cu12 24.12.0 requires pylibraft-cu12==24.12.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 24.12.0 requires rmm-cu12==24.12.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed bert-score-0.3.13 fsspec-2024.12.0 nvidia-cublas-cu12-12.4.5.8 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 portalocker-3.1.1 rouge-score-0.1.2 sacrebleu-2.5.1 transformers-4.47.0\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# Import libraries\nimport pandas as pd\nimport numpy as np\nfrom transformers import AutoTokenizer, AutoModelForCausalLM, Trainer, TrainingArguments\nfrom datasets import Dataset\nfrom sklearn.model_selection import train_test_split\nimport torch\nfrom nltk.translate.bleu_score import sentence_bleu\nfrom rouge_score import rouge_scorer\nimport bert_score\nimport warnings\nfrom transformers import TrainerCallback\nimport logging\nimport os\nwarnings.filterwarnings(\"ignore\")\n\nprint(\"Setup complete!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-09T10:49:27.681319Z","iopub.execute_input":"2025-05-09T10:49:27.681545Z","iopub.status.idle":"2025-05-09T10:49:52.732353Z","shell.execute_reply.started":"2025-05-09T10:49:27.681526Z","shell.execute_reply":"2025-05-09T10:49:52.731706Z"}},"outputs":[{"name":"stderr","text":"2025-05-09 10:49:38.670196: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1746787778.914486      31 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1746787778.985200      31 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"name":"stdout","text":"Setup complete!\n","output_type":"stream"}],"execution_count":3},{"cell_type":"markdown","source":"## Load DialoCONAN Dataset","metadata":{}},{"cell_type":"code","source":"# Load dataset\ndf = pd.read_csv(\"/kaggle/input/dialoconan/DIALOCONAN.csv\")  # Update path to your dataset\n\n# Display basic info\nprint(\"Dataset Shape:\", df.shape)\nprint(\"Columns:\", df.columns.tolist())\nprint(\"Unique Targets:\", df[\"TARGET\"].unique())\nprint(\"Unique Dialogue ID:\", df[\"dialogue_id\"].unique())\nprint(\"Unique Turn ID:\", df[\"turn_id\"].unique())\nprint(\"Unique Types:\", df[\"type\"].unique())\nprint(\"Unique Sources:\", df[\"source\"].unique())\nprint(\"Sample Data:\")\ndisplay(df.head())\n\n# Check dialogue distribution\nprint(\"Dialogue Count by Target:\")\nprint(df.groupby(\"TARGET\")[\"dialogue_id\"].nunique())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-09T10:49:52.733715Z","iopub.execute_input":"2025-05-09T10:49:52.734187Z","iopub.status.idle":"2025-05-09T10:49:52.849181Z","shell.execute_reply.started":"2025-05-09T10:49:52.734167Z","shell.execute_reply":"2025-05-09T10:49:52.848621Z"}},"outputs":[{"name":"stdout","text":"Dataset Shape: (16625, 6)\nColumns: ['text', 'TARGET', 'dialogue_id', 'turn_id', 'type', 'source']\nUnique Targets: ['MIGRANTS' 'POC' 'LGBT+' 'MUSLIMS' 'MIGRANTS/MUSLIMS' 'WOMEN' 'JEWS'\n 'WOMEN/POC' 'MUSLIMS/WOMEN' 'WOMEN/LGBT+']\nUnique Dialogue ID: [   0    1    2 ... 3050 3057 3048]\nUnique Turn ID: [0 1 2 3 4 5 6 7]\nUnique Types: ['HS' 'CN']\nUnique Sources: ['dialo_gold' 'session_1' 'session_2' 'session_3']\nSample Data:\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"                                                text    TARGET  dialogue_id  \\\n0  We’ve just imported 20k ticking time bombs fro...  MIGRANTS            0   \n1  Surely people who also risked their lives to h...  MIGRANTS            0   \n2  Our own must always come first. We have at lea...  MIGRANTS            0   \n3  We also have at least 1 million empty homes. T...  MIGRANTS            0   \n4  Our soldiers are left to rot on our streets wh...  MIGRANTS            0   \n\n   turn_id type      source  \n0        0   HS  dialo_gold  \n1        1   CN  dialo_gold  \n2        2   HS  dialo_gold  \n3        3   CN  dialo_gold  \n4        4   HS  dialo_gold  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>TARGET</th>\n      <th>dialogue_id</th>\n      <th>turn_id</th>\n      <th>type</th>\n      <th>source</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>We’ve just imported 20k ticking time bombs fro...</td>\n      <td>MIGRANTS</td>\n      <td>0</td>\n      <td>0</td>\n      <td>HS</td>\n      <td>dialo_gold</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Surely people who also risked their lives to h...</td>\n      <td>MIGRANTS</td>\n      <td>0</td>\n      <td>1</td>\n      <td>CN</td>\n      <td>dialo_gold</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Our own must always come first. We have at lea...</td>\n      <td>MIGRANTS</td>\n      <td>0</td>\n      <td>2</td>\n      <td>HS</td>\n      <td>dialo_gold</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>We also have at least 1 million empty homes. T...</td>\n      <td>MIGRANTS</td>\n      <td>0</td>\n      <td>3</td>\n      <td>CN</td>\n      <td>dialo_gold</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Our soldiers are left to rot on our streets wh...</td>\n      <td>MIGRANTS</td>\n      <td>0</td>\n      <td>4</td>\n      <td>HS</td>\n      <td>dialo_gold</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"name":"stdout","text":"Dialogue Count by Target:\nTARGET\nJEWS                468\nLGBT+               591\nMIGRANTS            534\nMIGRANTS/MUSLIMS      3\nMUSLIMS             505\nMUSLIMS/WOMEN         1\nPOC                 494\nWOMEN               462\nWOMEN/LGBT+           1\nWOMEN/POC             1\nName: dialogue_id, dtype: int64\n","output_type":"stream"}],"execution_count":4},{"cell_type":"markdown","source":"## Preprocess the data","metadata":{}},{"cell_type":"code","source":"def create_dialogue_pairs(df):\n    dialogues = []\n    for dialogue_id in df[\"dialogue_id\"].unique():\n        dialogue = df[df[\"dialogue_id\"] == dialogue_id].sort_values(\"turn_id\").reset_index(drop=True)\n        context = []\n        for _, row in dialogue.iterrows():\n            if row[\"type\"] == \"HS\":\n                context.append(f\"[{row['TARGET']} HS]: {row['text']}\")\n            elif row[\"type\"] == \"CN\":\n                # Find previous turn using turn_id\n                prev_turn = dialogue[dialogue[\"turn_id\"] == row[\"turn_id\"] - 1]\n                hs_text = \"\"\n                if not prev_turn.empty and prev_turn.iloc[0][\"type\"] == \"HS\":\n                    hs_text = prev_turn.iloc[0][\"text\"]\n                else:\n                    # Log warning and skip this pair\n                    logging.warning(f\"Dialogue {dialogue_id}, turn_id {row['turn_id']}: No valid preceding HS turn, skipping\")\n                    continue\n                \n                # Create sequence\n                input_seq = \" <|endoftext|> \".join(context[-5:]) if context else \"\"\n                full_seq = (input_seq + f\" <|endoftext|> [{row['TARGET']} HS]: {hs_text}\" if input_seq else f\"[{row['TARGET']} HS]: {hs_text}\") + f\" <|endoftext|> [{row['TARGET']} CN]: {row['text']} <|endoftext|>\"\n                dialogues.append({\n                    \"text\": full_seq,\n                    \"target\": row[\"TARGET\"],\n                    \"hs_text\": hs_text,\n                    \"cn_text\": row[\"text\"]\n                })\n                context.append(f\"[{row['TARGET']} CN]: {row['text']}\")\n    return dialogues\n\n# Create dialogue pairs\ndata = create_dialogue_pairs(df)\nprint(f\"Total Dialogue Pairs: {len(data)}\")\n\n# Split data\ntrain_data, temp_data = train_test_split(data, test_size=0.2, random_state=42)\nval_data, test_data = train_test_split(temp_data, test_size=0.5, random_state=42)\n\n# Convert to Hugging Face Dataset\ntrain_dataset = Dataset.from_list(train_data)\nval_dataset = Dataset.from_list(val_data)\ntest_dataset = Dataset.from_list(test_data)\n\nprint(f\"Train Size: {len(train_dataset)}, Val Size: {len(val_dataset)}, Test Size: {len(test_dataset)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-09T10:53:53.508498Z","iopub.execute_input":"2025-05-09T10:53:53.508984Z","iopub.status.idle":"2025-05-09T10:53:58.700735Z","shell.execute_reply.started":"2025-05-09T10:53:53.508962Z","shell.execute_reply":"2025-05-09T10:53:58.699927Z"}},"outputs":[{"name":"stdout","text":"Total Dialogue Pairs: 8309\nTrain Size: 6647, Val Size: 831, Test Size: 831\n","output_type":"stream"}],"execution_count":9},{"cell_type":"markdown","source":"## Tokenize Dataset","metadata":{}},{"cell_type":"code","source":"# Load tokenizer\nmodel_name = \"microsoft/DialoGPT-medium\"\ntokenizer = AutoTokenizer.from_pretrained(model_name)\ntokenizer.pad_token = tokenizer.eos_token  # Set pad token to eos_token\n\n# Tokenize function\ndef tokenize(batch):\n    encodings = tokenizer(\n        batch[\"text\"],\n        max_length=512,\n        truncation=True,\n        padding=\"max_length\",\n        return_tensors=\"np\"\n    )\n    return {\n        \"input_ids\": encodings.input_ids,\n        \"attention_mask\": encodings.attention_mask,\n        \"labels\": encodings.input_ids,  # For causal LM, labels are the same as input_ids\n        \"text\": batch[\"text\"],\n        \"target\": batch[\"target\"],\n        \"hs_text\": batch[\"hs_text\"],\n        \"cn_text\": batch[\"cn_text\"]\n    }\n\n# Apply tokenization\ntrain_dataset = train_dataset.map(tokenize, batched=True)\nval_dataset = val_dataset.map(tokenize, batched=True)\ntest_dataset = test_dataset.map(tokenize, batched=True)\n\n# Set format for training\ntrain_dataset.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\", \"text\", \"target\", \"hs_text\", \"cn_text\"])\nval_dataset.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\", \"text\", \"target\", \"hs_text\", \"cn_text\"])\ntest_dataset.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\", \"text\", \"target\", \"hs_text\", \"cn_text\"])\n\nprint(\"Tokenization complete!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-09T10:53:58.701852Z","iopub.execute_input":"2025-05-09T10:53:58.702147Z","iopub.status.idle":"2025-05-09T10:54:02.473588Z","shell.execute_reply.started":"2025-05-09T10:53:58.702089Z","shell.execute_reply":"2025-05-09T10:54:02.473006Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/614 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d9b6ba6a66e54969b5b43bd12b97fd2c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"17cf0cdd51ee47d3803d4800ffcedfed"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eb830665b2cd417eb277d787a2d6fbd6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/6647 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"33bda9f8b5c748bbb365200c843aab9a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/831 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"03742baf013b490fb7ecf802155352e6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/831 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"59577e988f9147629015a1fb32e52afe"}},"metadata":{}},{"name":"stdout","text":"Tokenization complete!\n","output_type":"stream"}],"execution_count":10},{"cell_type":"markdown","source":"## Initialize Model","metadata":{}},{"cell_type":"code","source":"# Load model\nmodel = AutoModelForCausalLM.from_pretrained(model_name)\n\n# Move to GPU if available\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)\n\nprint(f\"Model loaded on {device}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-09T10:54:03.832759Z","iopub.execute_input":"2025-05-09T10:54:03.833011Z","iopub.status.idle":"2025-05-09T10:54:10.032062Z","shell.execute_reply.started":"2025-05-09T10:54:03.832994Z","shell.execute_reply":"2025-05-09T10:54:10.031174Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/642 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5f68ea847d95404ea59261b664a6ee27"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/863M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d1e4c072ff6949619b8169239e1fe42c"}},"metadata":{}},{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a6df16768c0440d58e24f02b91ec85dd"}},"metadata":{}},{"name":"stdout","text":"Model loaded on cuda\n","output_type":"stream"}],"execution_count":11},{"cell_type":"markdown","source":"## Fine-Tune T5 Model","metadata":{}},{"cell_type":"code","source":"# Suppress warnings\nwarnings.filterwarnings(\"ignore\", message=\"Some weights of\")\n\n# Set up logging\nlogging.basicConfig(\n    format='%(asctime)s - %(levelname)s - %(message)s',\n    level=logging.INFO,\n    handlers=[\n        logging.StreamHandler(),\n        logging.FileHandler(\"/kaggle/working/training_logs.txt\")\n    ]\n)\nlogger = logging.getLogger(__name__)\n\n# Custom callback for validation metrics\nclass CustomMetricsCallback(TrainerCallback):\n    def __init__(self, tokenizer, val_dataset, max_samples=100):\n        self.tokenizer = tokenizer\n        self.val_dataset = val_dataset.select(range(min(max_samples, len(val_dataset))))\n        self.scorer = rouge_scorer.RougeScorer([\"rougeL\"], use_stemmer=True)\n\n    def on_evaluate(self, args, state, control, model, **kwargs):\n        logger.info(f\"Computing custom metrics at step {state.global_step}\")\n        bleu_scores, rouge_scores, bert_scores = [], [], []\n        \n        model.eval()\n        for item in self.val_dataset:\n            try:\n                input_text = item[\"text\"].split(\" <|endoftext|> \")[:-1]  # Remove CN part\n                input_text = \" <|endoftext|> \".join(input_text)\n                target = item[\"target\"]\n                \n                # Generate prediction\n                inputs = self.tokenizer(\n                    input_text + f\" <|endoftext|> [{target} CN]:\",\n                    return_tensors=\"pt\",\n                    max_length=512,\n                    truncation=True\n                ).to(model.device)\n                outputs = model.generate(\n                    inputs[\"input_ids\"],\n                    max_length=512,\n                    num_beams=5,\n                    no_repeat_ngram_size=2,\n                    early_stopping=True\n                )\n                pred = self.tokenizer.decode(outputs[0], skip_special_tokens=True)\n                pred = pred.split(f\"[{target} CN]:\")[-1].strip() if f\"[{target} CN]:\" in pred else pred\n                ref = item[\"cn_text\"]\n                \n                # Compute metrics\n                bleu_scores.append(sentence_bleu([ref.split()], pred.split()))\n                rouge_scores.append(self.scorer.score(ref, pred)[\"rougeL\"].fmeasure)\n                P, R, F1 = bert_score.score([pred], [ref], lang=\"en\", rescale_with_baseline=True)\n                bert_scores.append(F1.item())\n            except Exception as e:\n                logger.warning(f\"Error processing item: {e}\")\n                continue\n        \n        # Log metrics\n        metrics = {\n            \"val_bleu\": np.mean(bleu_scores) if bleu_scores else 0.0,\n            \"val_rouge_l\": np.mean(rouge_scores) if rouge_scores else 0.0,\n            \"val_bertscore\": np.mean(bert_scores) if bert_scores else 0.0\n        }\n        logger.info(f\"Validation Metrics: {metrics}\")\n        return None\n\n# Training arguments\ntraining_args = TrainingArguments(\n    output_dir=\"/kaggle/working/dialogpt-counterspeech\",\n    num_train_epochs=5,\n    per_device_train_batch_size=2,\n    per_device_eval_batch_size=2,\n    warmup_steps=500,\n    weight_decay=0.01,\n    logging_dir=\"/kaggle/working/logs\",\n    logging_steps=100,\n    evaluation_strategy=\"epoch\",\n    save_strategy=\"epoch\",\n    load_best_model_at_end=True,\n    save_total_limit=1,\n    fp16=True,\n    report_to=\"none\",\n)\n\n# Initialize trainer\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_dataset,\n    eval_dataset=val_dataset,\n    callbacks=[CustomMetricsCallback(tokenizer, val_dataset)]\n)\n\n# Train model\nlogger.info(\"Starting training...\")\ntrainer.train()\n\n# Save model\nmodel.save_pretrained(\"/kaggle/working/dialogpt-counterspeech-final\")\ntokenizer.save_pretrained(\"/kaggle/working/dialogpt-counterspeech-final\")\n\n# Save logs\nwith open(\"/kaggle/working/final_training_logs.txt\", \"w\") as f:\n    f.write(str(trainer.state.log_history))\n\nprint(\"Training complete! Check /kaggle/working/training_logs.txt for detailed logs.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-09T10:56:34.091545Z","iopub.execute_input":"2025-05-09T10:56:34.091820Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='38' max='8310' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [  38/8310 00:42 < 2:43:15, 0.84 it/s, Epoch 0.02/5]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>"},"metadata":{}}],"execution_count":null},{"cell_type":"markdown","source":"## Plot training/validation loss","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nlogs = trainer.state.log_history\nsteps = [log[\"step\"] for log in logs if \"loss\" in log]\nlosses = [log[\"loss\"] for log in logs if \"loss\" in log]\nplt.plot(steps, losses, label=\"Training Loss\")\nplt.xlabel(\"Batch Steps\")\nplt.ylabel(\"Loss\")\nplt.legend()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-09T10:49:53.131663Z","iopub.status.idle":"2025-05-09T10:49:53.131880Z","shell.execute_reply.started":"2025-05-09T10:49:53.131783Z","shell.execute_reply":"2025-05-09T10:49:53.131792Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Generate Counterspeech on test-split","metadata":{}},{"cell_type":"code","source":"def generate_counterspeech(hs_text, target, dialogue_history=None):\n    # Prepare input\n    input_text = f\"[{target} HS]: {hs_text} <|endoftext|> [{target} CN]:\" if not dialogue_history else f\"{dialogue_history} <|endoftext|> [{target} HS]: {hs_text} <|endoftext|> [{target} CN]:\"\n    \n    # Tokenize\n    inputs = tokenizer(\n        input_text,\n        return_tensors=\"pt\",\n        max_length=512,\n        truncation=True\n    ).to(device)\n    \n    # Generate\n    outputs = model.generate(\n        inputs[\"input_ids\"],\n        max_length=512,\n        num_beams=5,\n        no_repeat_ngram_size=2,\n        early_stopping=True\n    )\n    \n    # Decode\n    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n    response = response.split(f\"[{target} CN]:\")[-1].strip() if f\"[{target} CN]:\" in response else response\n    return response\n\n# Test inference\nsample_hs = \"All migrants are criminals and should be deported!\"\nsample_target = \"MIGRANTS\"\nsample_history = \"[MIGRANTS HS]: More migrants crossing the channel today. We don’t have enough accommodation. <|endoftext|> [MIGRANTS CN]: Are you forgetting that last year every rough sleeper was offered a bed during lockdown?\"\ngenerated_cn = generate_counterspeech(sample_hs, sample_target, sample_history)\nprint(f\"Hate Speech: {sample_hs}\")\nprint(f\"Generated Counterspeech: {generated_cn}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-09T10:49:53.132720Z","iopub.status.idle":"2025-05-09T10:49:53.133068Z","shell.execute_reply.started":"2025-05-09T10:49:53.132925Z","shell.execute_reply":"2025-05-09T10:49:53.132941Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Evaluate Model","metadata":{}},{"cell_type":"code","source":"def evaluate_model(dataset):\n    bleu_scores = []\n    rouge_scores = []\n    bert_scores = []\n    scorer = rouge_scorer.RougeScorer([\"rougeL\"], use_stemmer=True)\n    \n    for item in dataset:\n        # Generate prediction\n        hs_text = item[\"hs_text\"]\n        dialogue_history = \" <|endoftext|> \".join(item[\"text\"].split(\" <|endoftext|> \")[:-2])  # Exclude CN part\n        pred = generate_counterspeech(hs_text, item[\"target\"], dialogue_history)\n        ref = item[\"cn_text\"]\n        \n        # BLEU\n        bleu_scores.append(sentence_bleu([ref.split()], pred.split()))\n        \n        # ROUGE\n        rouge_scores.append(scorer.score(ref, pred)[\"rougeL\"].fmeasure)\n        \n        # BERTScore\n        P, R, F1 = bert_score.score([pred], [ref], lang=\"en\", rescale_with_baseline=True)\n        bert_scores.append(F1.item())\n    \n    return {\n        \"BLEU\": np.mean(bleu_scores),\n        \"ROUGE-L\": np.mean(rouge_scores),\n        \"BERTScore\": np.mean(bert_scores)\n    }\n\n# Run evaluation\nresults = evaluate_model(test_dataset)\nprint(\"Evaluation Results:\")\nfor metric, score in results.items():\n    print(f\"{metric}: {score:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-09T10:49:53.134077Z","iopub.status.idle":"2025-05-09T10:49:53.134360Z","shell.execute_reply.started":"2025-05-09T10:49:53.134246Z","shell.execute_reply":"2025-05-09T10:49:53.134259Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Save Results","metadata":{}},{"cell_type":"code","source":"# Save evaluation results\nimport json\nwith open(\"/kaggle/working/evaluation_results.json\", \"w\") as f:\n    json.dump(results, f, indent=4)\n\n# Save sample predictions\npredictions = []\nfor item in test_dataset.select(range(5)):\n    hs_text = item[\"hs_text\"]\n    dialogue_history = \" <|endoftext|> \".join(item[\"text\"].split(\" <|endoftext|> \")[:-2])\n    pred = generate_counterspeech(hs_text, item[\"target\"], dialogue_history)\n    predictions.append({\n        \"input\": item[\"text\"],\n        \"hate_speech\": hs_text,\n        \"target\": item[\"target\"],\n        \"predicted_counterspeech\": pred,\n        \"reference_counterspeech\": item[\"cn_text\"]\n    })\n\npd.DataFrame(predictions).to_csv(\"/kaggle/working/sample_predictions.csv\", index=False)\nprint(\"Results and predictions saved!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-09T10:49:53.135340Z","iopub.status.idle":"2025-05-09T10:49:53.135629Z","shell.execute_reply.started":"2025-05-09T10:49:53.135461Z","shell.execute_reply":"2025-05-09T10:49:53.135476Z"}},"outputs":[],"execution_count":null}]}